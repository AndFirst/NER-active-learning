{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T22:59:46.949094Z",
     "start_time": "2024-05-26T22:59:46.512376Z"
    }
   },
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T22:59:47.681963Z",
     "start_time": "2024-05-26T22:59:46.950498Z"
    }
   },
   "source": [
    "data = pd.read_csv(\"/home/irek/PycharmProjects/zprp-ner-active_learning/data/processed/ner_dataset.csv\")\n",
    "data = data.fillna(method=\"ffill\")\n",
    "data.head(20)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4319/4220236873.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data = data.fillna(method=\"ffill\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     Sentence #           Word  POS    Tag\n",
       "0   Sentence: 1      Thousands  NNS      O\n",
       "1   Sentence: 1             of   IN      O\n",
       "2   Sentence: 1  demonstrators  NNS      O\n",
       "3   Sentence: 1           have  VBP      O\n",
       "4   Sentence: 1        marched  VBN      O\n",
       "5   Sentence: 1        through   IN      O\n",
       "6   Sentence: 1         London  NNP  B-geo\n",
       "7   Sentence: 1             to   TO      O\n",
       "8   Sentence: 1        protest   VB      O\n",
       "9   Sentence: 1            the   DT      O\n",
       "10  Sentence: 1            war   NN      O\n",
       "11  Sentence: 1             in   IN      O\n",
       "12  Sentence: 1           Iraq  NNP  B-geo\n",
       "13  Sentence: 1            and   CC      O\n",
       "14  Sentence: 1         demand   VB      O\n",
       "15  Sentence: 1            the   DT      O\n",
       "16  Sentence: 1     withdrawal   NN      O\n",
       "17  Sentence: 1             of   IN      O\n",
       "18  Sentence: 1        British   JJ  B-gpe\n",
       "19  Sentence: 1         troops  NNS      O"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>war</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demand</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>withdrawal</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>British</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>troops</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T22:59:47.813412Z",
     "start_time": "2024-05-26T22:59:47.683091Z"
    }
   },
   "source": [
    "print(\"Unique words in corpus:\", data[\"Word\"].nunique())\n",
    "print(\"Unique tags in corpus:\", data[\"Tag\"].nunique())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in corpus: 35171\n",
      "Unique tags in corpus: 17\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T22:59:47.910809Z",
     "start_time": "2024-05-26T22:59:47.840336Z"
    }
   },
   "source": [
    "words = [\"<PAD>\"]\n",
    "words.extend(list(set(data[\"Word\"].values)))\n",
    "num_words = len(words)\n",
    "\n",
    "tags = list(set(data[\"Tag\"].values))\n",
    "num_tags = len(tags)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T22:59:53.653548Z",
     "start_time": "2024-05-26T22:59:50.430966Z"
    }
   },
   "source": [
    "def sentence_integrate(data):\n",
    "    def agg_func(s):\n",
    "        return [\n",
    "            (w, p, t)\n",
    "            for w, p, t in zip(\n",
    "                s[\"Word\"].values.tolist(),\n",
    "                s[\"POS\"].values.tolist(),\n",
    "                s[\"Tag\"].values.tolist(),\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    return data.groupby(\"Sentence #\").apply(agg_func).tolist()\n",
    "\n",
    "\n",
    "sentences = sentence_integrate(data)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4319/538150070.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return data.groupby(\"Sentence #\").apply(agg_func).tolist()\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.histogram(\n",
    "    pd.DataFrame([len(s) for s in sentences], columns=[\"length\"]),\n",
    "    x=\"length\",\n",
    "    marginal=\"box\",\n",
    ")\n",
    "fig.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T22:59:54.522350Z",
     "start_time": "2024-05-26T22:59:54.516119Z"
    }
   },
   "source": [
    "sentences[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thousands', 'NNS', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('demonstrators', 'NNS', 'O'),\n",
       " ('have', 'VBP', 'O'),\n",
       " ('marched', 'VBN', 'O'),\n",
       " ('through', 'IN', 'O'),\n",
       " ('London', 'NNP', 'B-geo'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('protest', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('war', 'NN', 'O'),\n",
       " ('in', 'IN', 'O'),\n",
       " ('Iraq', 'NNP', 'B-geo'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('demand', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('withdrawal', 'NN', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('British', 'JJ', 'B-gpe'),\n",
       " ('troops', 'NNS', 'O'),\n",
       " ('from', 'IN', 'O'),\n",
       " ('that', 'DT', 'O'),\n",
       " ('country', 'NN', 'O'),\n",
       " ('.', '.', 'O')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T22:59:55.438975Z",
     "start_time": "2024-05-26T22:59:55.313002Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "# word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "with open(\"/home/irek/PycharmProjects/zprp-ner-active_learning/dupa/words_to_idx.json\") as f:\n",
    "    word2idx = json.load(f)"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/irek/PycharmProjects/zprp-ner-active_learning/dupa/words_to_idx.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# word2idx = {w: i for i, w in enumerate(words)}\u001B[39;00m\n\u001B[1;32m      4\u001B[0m tag2idx \u001B[38;5;241m=\u001B[39m {t: i \u001B[38;5;28;01mfor\u001B[39;00m i, t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(tags)}\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/home/irek/PycharmProjects/zprp-ner-active_learning/dupa/words_to_idx.json\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m      6\u001B[0m     word2idx \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mload(f)\n",
      "File \u001B[0;32m~/PycharmProjects/zprp-ner-active_learning/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001B[0m, in \u001B[0;36m_modified_open\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[1;32m    318\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    319\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    320\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    321\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    322\u001B[0m     )\n\u001B[0;32m--> 324\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/home/irek/PycharmProjects/zprp-ner-active_learning/dupa/words_to_idx.json'"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T22:59:56.153687Z",
     "start_time": "2024-05-26T22:59:56.150440Z"
    }
   },
   "source": [
    "tag2idx"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-per': 1,\n",
       " 'B-org': 2,\n",
       " 'I-gpe': 3,\n",
       " 'I-eve': 4,\n",
       " 'I-nat': 5,\n",
       " 'B-geo': 6,\n",
       " 'I-org': 7,\n",
       " 'I-per': 8,\n",
       " 'B-eve': 9,\n",
       " 'I-tim': 10,\n",
       " 'I-geo': 11,\n",
       " 'B-art': 12,\n",
       " 'B-gpe': 13,\n",
       " 'B-tim': 14,\n",
       " 'I-art': 15,\n",
       " 'B-nat': 16}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T22:59:59.486938Z",
     "start_time": "2024-05-26T22:59:57.940304Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "import hashlib\n",
    "\n",
    "\n",
    "def hash_string(s: str) -> int:\n",
    "    return int(hashlib.sha256(s.encode()).hexdigest(), 16) % 100_001\n",
    "\n",
    "\n",
    "max_len = 50\n",
    "X = [[hash_string(w[0]) for w in s] for s in sentences]\n",
    "Y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
    "\n",
    "X = np.array([x[:max_len] + [num_words - 1] * (max_len - len(x)) for x in X])\n",
    "Y = np.array([y[:max_len] + [tag2idx[\"O\"]] * (max_len - len(y)) for y in Y])\n",
    "X.shape, Y.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47959, 50), (47959, 50))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:59:19.916821Z",
     "start_time": "2024-05-26T20:59:19.911593Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35172"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:00:03.345490Z",
     "start_time": "2024-05-26T23:00:02.530338Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:00:04.827772Z",
     "start_time": "2024-05-26T23:00:03.347204Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_words,\n",
    "            num_classes=17,\n",
    "            embedding_dim=100,\n",
    "            lstm_units=100,\n",
    "            dropout=0.1,\n",
    "    ):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(100_000, embedding_dim)\n",
    "        self.bn = nn.BatchNorm1d(embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            lstm_units,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        self.linear = nn.Linear(lstm_units * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        embedded = self.dropout(embedded)\n",
    "        embedded = self.bn(embedded.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        lstm_output, _ = self.lstm(embedded)\n",
    "        logits = self.linear(lstm_output)\n",
    "        probabilities = F.softmax(logits, dim=2)\n",
    "        return probabilities"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:00:04.868863Z",
     "start_time": "2024-05-26T23:00:04.829453Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:00:04.983667Z",
     "start_time": "2024-05-26T23:00:04.869914Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "tag_counts = data[\"Tag\"].value_counts()\n",
    "print(tag_counts)\n",
    "# policz sumę wszystkich wystąpień\n",
    "total_count = tag_counts.sum()\n",
    "\n",
    "# policz wagi dla każdego tagu\n",
    "tag_weights = total_count / tag_counts\n",
    "tag_weights = list(tag_weights.items())\n",
    "tag_weights = sorted(tag_weights, key=lambda x: tag2idx[x[0]])\n",
    "tag_weights = torch.tensor([w[1] for w in tag_weights])\n",
    "tag_weights"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag\n",
      "O        887908\n",
      "B-geo     37644\n",
      "B-tim     20333\n",
      "B-org     20143\n",
      "I-per     17251\n",
      "B-per     16990\n",
      "I-org     16784\n",
      "B-gpe     15870\n",
      "I-geo      7414\n",
      "I-tim      6528\n",
      "B-art       402\n",
      "B-eve       308\n",
      "I-art       297\n",
      "I-eve       253\n",
      "B-nat       201\n",
      "I-gpe       198\n",
      "I-nat        51\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.1810e+00, 6.1717e+01, 5.2057e+01, 5.2958e+03, 4.1446e+03, 2.0560e+04,\n",
       "        2.7855e+01, 6.2475e+01, 6.0783e+01, 3.4045e+03, 1.6063e+02, 1.4143e+02,\n",
       "        2.6084e+03, 6.6073e+01, 5.1570e+01, 3.5306e+03, 5.2168e+03])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:00:05.811173Z",
     "start_time": "2024-05-26T23:00:05.798536Z"
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def eval(model, eval_loader, loss_func, verbose=True, return_values=False):\n",
    "    running_loss = 0.0\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in eval_loader:\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.view(-1, outputs.size(2))\n",
    "            labels = labels.view(-1)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted_test = torch.max(outputs, 1)\n",
    "            predicted_labels.extend(predicted_test.tolist())\n",
    "            true_labels.extend(labels.tolist())\n",
    "    loss = running_loss / len(eval_loader)\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, average=\"macro\")\n",
    "    recall = recall_score(true_labels, predicted_labels, average=\"macro\")\n",
    "    f1 = f1_score(true_labels, predicted_labels, average=\"macro\")\n",
    "    if verbose:\n",
    "        print(f\"Loss: {loss:.4f}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-score: {f1:.4f}\")\n",
    "        print(\"----------------------------------\")\n",
    "    if return_values:\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "        }"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:05:39.147105Z",
     "start_time": "2024-05-26T23:03:39.597183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Funkcja do dzielenia macierzy na listę mniejszych macierzy\n",
    "def split_array(array, chunk_size):\n",
    "    return [array[i:i + chunk_size] for i in range(0, len(array), chunk_size)]\n",
    "\n",
    "\n",
    "# Dzielimy x_train i y_train\n",
    "chunk_size = 32\n",
    "x_train_chunks = split_array(x_train, chunk_size)\n",
    "y_train_chunks = split_array(y_train, chunk_size)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "x_test_tensor = torch.LongTensor(x_test).to(device)\n",
    "y_test_tensor = torch.LongTensor(y_test).to(device)\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "current_x_train = []\n",
    "current_y_train = []\n",
    "model = BiLSTM(num_words).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=tag_weights.to(device))\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for idx, (x_chunk, y_chunk) in enumerate(zip(x_train_chunks, y_train_chunks)):\n",
    "    current_x_train.extend(x_chunk), current_y_train.extend(y_chunk)\n",
    "\n",
    "    x_train_tensor = torch.LongTensor(current_x_train).to(device)\n",
    "    y_train_tensor = torch.LongTensor(current_y_train).to(device)\n",
    "\n",
    "    train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    epochs = 20\n",
    "    print(f\"------Chunk {idx + 1}/{len(x_train_chunks)}--------\")\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            # Spłaszczenie do dwóch wymiarów\n",
    "            outputs = outputs.view(-1, outputs.size(2))\n",
    "            labels = labels.view(-1)  # Spłaszczenie do jednego wymiaru\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    eval(model, test_loader, criterion, True, False)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Chunk 1/1199--------\n",
      "Loss: 2.7481\n",
      "Accuracy: 0.5712\n",
      "Precision: 0.1263\n",
      "Recall: 0.1148\n",
      "F1-score: 0.0677\n",
      "----------------------------------\n",
      "------Chunk 2/1199--------\n",
      "Loss: 2.6961\n",
      "Accuracy: 0.5877\n",
      "Precision: 0.0817\n",
      "Recall: 0.1688\n",
      "F1-score: 0.0775\n",
      "----------------------------------\n",
      "------Chunk 3/1199--------\n",
      "Loss: 2.6497\n",
      "Accuracy: 0.6089\n",
      "Precision: 0.0871\n",
      "Recall: 0.2038\n",
      "F1-score: 0.0905\n",
      "----------------------------------\n",
      "------Chunk 4/1199--------\n",
      "Loss: 2.6319\n",
      "Accuracy: 0.6280\n",
      "Precision: 0.0836\n",
      "Recall: 0.2147\n",
      "F1-score: 0.0892\n",
      "----------------------------------\n",
      "------Chunk 5/1199--------\n",
      "Loss: 2.6235\n",
      "Accuracy: 0.8742\n",
      "Precision: 0.1626\n",
      "Recall: 0.1989\n",
      "F1-score: 0.1688\n",
      "----------------------------------\n",
      "------Chunk 6/1199--------\n",
      "Loss: 2.6107\n",
      "Accuracy: 0.9208\n",
      "Precision: 0.2220\n",
      "Recall: 0.2048\n",
      "F1-score: 0.2054\n",
      "----------------------------------\n",
      "------Chunk 7/1199--------\n",
      "Loss: 2.6016\n",
      "Accuracy: 0.9354\n",
      "Precision: 0.2634\n",
      "Recall: 0.2125\n",
      "F1-score: 0.2283\n",
      "----------------------------------\n",
      "------Chunk 8/1199--------\n",
      "Loss: 2.5740\n",
      "Accuracy: 0.9380\n",
      "Precision: 0.2991\n",
      "Recall: 0.2414\n",
      "F1-score: 0.2631\n",
      "----------------------------------\n",
      "------Chunk 9/1199--------\n",
      "Loss: 2.5679\n",
      "Accuracy: 0.9433\n",
      "Precision: 0.3393\n",
      "Recall: 0.2478\n",
      "F1-score: 0.2780\n",
      "----------------------------------\n",
      "------Chunk 10/1199--------\n",
      "Loss: 2.5610\n",
      "Accuracy: 0.9453\n",
      "Precision: 0.3624\n",
      "Recall: 0.2535\n",
      "F1-score: 0.2881\n",
      "----------------------------------\n",
      "------Chunk 11/1199--------\n",
      "Loss: 2.5433\n",
      "Accuracy: 0.9468\n",
      "Precision: 0.3560\n",
      "Recall: 0.2710\n",
      "F1-score: 0.2996\n",
      "----------------------------------\n",
      "------Chunk 12/1199--------\n",
      "Loss: 2.5392\n",
      "Accuracy: 0.9489\n",
      "Precision: 0.3814\n",
      "Recall: 0.2744\n",
      "F1-score: 0.3095\n",
      "----------------------------------\n",
      "------Chunk 13/1199--------\n",
      "Loss: 2.5263\n",
      "Accuracy: 0.9497\n",
      "Precision: 0.3831\n",
      "Recall: 0.2860\n",
      "F1-score: 0.3163\n",
      "----------------------------------\n",
      "------Chunk 14/1199--------\n",
      "Loss: 2.5096\n",
      "Accuracy: 0.9482\n",
      "Precision: 0.3629\n",
      "Recall: 0.3018\n",
      "F1-score: 0.3204\n",
      "----------------------------------\n",
      "------Chunk 15/1199--------\n",
      "Loss: 2.5113\n",
      "Accuracy: 0.9524\n",
      "Precision: 0.3915\n",
      "Recall: 0.2996\n",
      "F1-score: 0.3303\n",
      "----------------------------------\n",
      "------Chunk 16/1199--------\n",
      "Loss: 2.5005\n",
      "Accuracy: 0.9526\n",
      "Precision: 0.3749\n",
      "Recall: 0.3090\n",
      "F1-score: 0.3318\n",
      "----------------------------------\n",
      "------Chunk 17/1199--------\n",
      "Loss: 2.4940\n",
      "Accuracy: 0.9501\n",
      "Precision: 0.3973\n",
      "Recall: 0.3177\n",
      "F1-score: 0.3250\n",
      "----------------------------------\n",
      "------Chunk 18/1199--------\n",
      "Loss: 2.4870\n",
      "Accuracy: 0.9538\n",
      "Precision: 0.3822\n",
      "Recall: 0.3223\n",
      "F1-score: 0.3400\n",
      "----------------------------------\n",
      "------Chunk 19/1199--------\n",
      "Loss: 2.4887\n",
      "Accuracy: 0.9556\n",
      "Precision: 0.4505\n",
      "Recall: 0.3205\n",
      "F1-score: 0.3466\n",
      "----------------------------------\n",
      "------Chunk 20/1199--------\n",
      "Loss: 2.4801\n",
      "Accuracy: 0.9557\n",
      "Precision: 0.4703\n",
      "Recall: 0.3277\n",
      "F1-score: 0.3523\n",
      "----------------------------------\n",
      "------Chunk 21/1199--------\n",
      "Loss: 2.4712\n",
      "Accuracy: 0.9550\n",
      "Precision: 0.4211\n",
      "Recall: 0.3395\n",
      "F1-score: 0.3587\n",
      "----------------------------------\n",
      "------Chunk 22/1199--------\n",
      "Loss: 2.4517\n",
      "Accuracy: 0.9517\n",
      "Precision: 0.3872\n",
      "Recall: 0.3572\n",
      "F1-score: 0.3491\n",
      "----------------------------------\n",
      "------Chunk 23/1199--------\n",
      "Loss: 2.4515\n",
      "Accuracy: 0.9520\n",
      "Precision: 0.4183\n",
      "Recall: 0.3576\n",
      "F1-score: 0.3536\n",
      "----------------------------------\n",
      "------Chunk 24/1199--------\n",
      "Loss: 2.4538\n",
      "Accuracy: 0.9552\n",
      "Precision: 0.4153\n",
      "Recall: 0.3554\n",
      "F1-score: 0.3681\n",
      "----------------------------------\n",
      "------Chunk 25/1199--------\n",
      "Loss: 2.4452\n",
      "Accuracy: 0.9556\n",
      "Precision: 0.3851\n",
      "Recall: 0.3636\n",
      "F1-score: 0.3691\n",
      "----------------------------------\n",
      "------Chunk 26/1199--------\n",
      "Loss: 2.4381\n",
      "Accuracy: 0.9572\n",
      "Precision: 0.4127\n",
      "Recall: 0.3710\n",
      "F1-score: 0.3818\n",
      "----------------------------------\n",
      "------Chunk 27/1199--------\n",
      "Loss: 2.4353\n",
      "Accuracy: 0.9590\n",
      "Precision: 0.4142\n",
      "Recall: 0.3717\n",
      "F1-score: 0.3834\n",
      "----------------------------------\n",
      "------Chunk 28/1199--------\n",
      "Loss: 2.4356\n",
      "Accuracy: 0.9586\n",
      "Precision: 0.4182\n",
      "Recall: 0.3726\n",
      "F1-score: 0.3833\n",
      "----------------------------------\n",
      "------Chunk 29/1199--------\n",
      "Loss: 2.4294\n",
      "Accuracy: 0.9584\n",
      "Precision: 0.4310\n",
      "Recall: 0.3789\n",
      "F1-score: 0.3881\n",
      "----------------------------------\n",
      "------Chunk 30/1199--------\n",
      "Loss: 2.4279\n",
      "Accuracy: 0.9597\n",
      "Precision: 0.4258\n",
      "Recall: 0.3790\n",
      "F1-score: 0.3894\n",
      "----------------------------------\n",
      "------Chunk 31/1199--------\n",
      "Loss: 2.4291\n",
      "Accuracy: 0.9605\n",
      "Precision: 0.4365\n",
      "Recall: 0.3772\n",
      "F1-score: 0.3925\n",
      "----------------------------------\n",
      "------Chunk 32/1199--------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 55\u001B[0m\n\u001B[1;32m     52\u001B[0m         labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# Spłaszczenie do jednego wymiaru\u001B[39;00m\n\u001B[1;32m     54\u001B[0m         loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels)\n\u001B[0;32m---> 55\u001B[0m         \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m         optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28meval\u001B[39m(model, test_loader, criterion, \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/PycharmProjects/zprp-ner-active_learning/.venv/lib/python3.12/site-packages/torch/_tensor.py:525\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    517\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    518\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    523\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    524\u001B[0m     )\n\u001B[0;32m--> 525\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/zprp-ner-active_learning/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    262\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    266\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 267\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/zprp-ner-active_learning/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    742\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    743\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 744\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    745\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    746\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    747\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    748\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T22:26:41.408632Z",
     "start_time": "2024-05-26T22:21:07.884480Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "x_train_tensor = torch.LongTensor(x_train).to(device)\n",
    "y_train_tensor = torch.LongTensor(y_train).to(device)\n",
    "x_test_tensor = torch.LongTensor(x_test).to(device)\n",
    "y_test_tensor = torch.LongTensor(y_test).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "model = BiLSTM(num_words).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=tag_weights.to(device))\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        # Spłaszczenie do dwóch wymiarów\n",
    "        outputs = outputs.view(-1, outputs.size(2))\n",
    "        labels = labels.view(-1)  # Spłaszczenie do jednego wymiaru\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}----------------------\")\n",
    "    print(\"Train dataset:\")\n",
    "    eval(model, train_loader, criterion, True, False)\n",
    "    print(\"Eval dataset:\")\n",
    "    eval(model, test_loader, criterion, True, False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20----------------------\n",
      "Train dataset:\n",
      "Loss: 2.2426\n",
      "Accuracy: 0.8647\n",
      "Precision: 0.2458\n",
      "Recall: 0.5754\n",
      "F1-score: 0.3141\n",
      "----------------------------------\n",
      "Eval dataset:\n",
      "Loss: 2.2952\n",
      "Accuracy: 0.8649\n",
      "Precision: 0.2386\n",
      "Recall: 0.5583\n",
      "F1-score: 0.3032\n",
      "----------------------------------\n",
      "Epoch 2/20----------------------\n",
      "Train dataset:\n",
      "Loss: 2.1879\n",
      "Accuracy: 0.9062\n",
      "Precision: 0.3455\n",
      "Recall: 0.6293\n",
      "F1-score: 0.3701\n",
      "----------------------------------\n",
      "Eval dataset:\n",
      "Loss: 2.2498\n",
      "Accuracy: 0.9040\n",
      "Precision: 0.2759\n",
      "Recall: 0.5999\n",
      "F1-score: 0.3559\n",
      "----------------------------------\n",
      "Epoch 3/20----------------------\n",
      "Train dataset:\n",
      "Loss: 2.1521\n",
      "Accuracy: 0.9340\n",
      "Precision: 0.3574\n",
      "Recall: 0.6726\n",
      "F1-score: 0.4376\n",
      "----------------------------------\n",
      "Eval dataset:\n",
      "Loss: 2.2275\n",
      "Accuracy: 0.9309\n",
      "Precision: 0.3400\n",
      "Recall: 0.6217\n",
      "F1-score: 0.4152\n",
      "----------------------------------\n",
      "Epoch 4/20----------------------\n",
      "Train dataset:\n",
      "Loss: 2.1238\n",
      "Accuracy: 0.9454\n",
      "Precision: 0.4410\n",
      "Recall: 0.7086\n",
      "F1-score: 0.4718\n",
      "----------------------------------\n",
      "Eval dataset:\n",
      "Loss: 2.2133\n",
      "Accuracy: 0.9414\n",
      "Precision: 0.3616\n",
      "Recall: 0.6336\n",
      "F1-score: 0.4386\n",
      "----------------------------------\n",
      "Epoch 5/20----------------------\n",
      "Train dataset:\n",
      "Loss: 2.1055\n",
      "Accuracy: 0.9494\n",
      "Precision: 0.4068\n",
      "Recall: 0.7420\n",
      "F1-score: 0.4882\n",
      "----------------------------------\n",
      "Eval dataset:\n",
      "Loss: 2.2057\n",
      "Accuracy: 0.9448\n",
      "Precision: 0.3738\n",
      "Recall: 0.6449\n",
      "F1-score: 0.4479\n",
      "----------------------------------\n",
      "Epoch 6/20----------------------\n",
      "Train dataset:\n",
      "Loss: 2.0783\n",
      "Accuracy: 0.9526\n",
      "Precision: 0.4200\n",
      "Recall: 0.7888\n",
      "F1-score: 0.5080\n",
      "----------------------------------\n",
      "Eval dataset:\n",
      "Loss: 2.1990\n",
      "Accuracy: 0.9471\n",
      "Precision: 0.3903\n",
      "Recall: 0.6515\n",
      "F1-score: 0.4636\n",
      "----------------------------------\n",
      "Epoch 7/20----------------------\n",
      "Train dataset:\n",
      "Loss: 2.0668\n",
      "Accuracy: 0.9560\n",
      "Precision: 0.4640\n",
      "Recall: 0.8142\n",
      "F1-score: 0.5404\n",
      "----------------------------------\n",
      "Eval dataset:\n",
      "Loss: 2.1890\n",
      "Accuracy: 0.9503\n",
      "Precision: 0.4196\n",
      "Recall: 0.6666\n",
      "F1-score: 0.4841\n",
      "----------------------------------\n",
      "Epoch 8/20----------------------\n",
      "Train dataset:\n",
      "Loss: 2.0543\n",
      "Accuracy: 0.9645\n",
      "Precision: 0.4926\n",
      "Recall: 0.8298\n",
      "F1-score: 0.5779\n",
      "----------------------------------\n",
      "Eval dataset:\n",
      "Loss: 2.1890\n",
      "Accuracy: 0.9589\n",
      "Precision: 0.4370\n",
      "Recall: 0.6685\n",
      "F1-score: 0.5074\n",
      "----------------------------------\n",
      "Epoch 9/20----------------------\n",
      "Train dataset:\n",
      "Loss: 2.0456\n",
      "Accuracy: 0.9643\n",
      "Precision: 0.4743\n",
      "Recall: 0.8585\n",
      "F1-score: 0.5752\n",
      "----------------------------------\n",
      "Eval dataset:\n",
      "Loss: 2.1850\n",
      "Accuracy: 0.9580\n",
      "Precision: 0.4198\n",
      "Recall: 0.6768\n",
      "F1-score: 0.4999\n",
      "----------------------------------\n",
      "Epoch 10/20----------------------\n",
      "Train dataset:\n",
      "Loss: 2.0349\n",
      "Accuracy: 0.9665\n",
      "Precision: 0.4888\n",
      "Recall: 0.8704\n",
      "F1-score: 0.5844\n",
      "----------------------------------\n",
      "Eval dataset:\n",
      "Loss: 2.1841\n",
      "Accuracy: 0.9597\n",
      "Precision: 0.4244\n",
      "Recall: 0.6694\n",
      "F1-score: 0.4964\n",
      "----------------------------------\n",
      "Epoch 11/20----------------------\n",
      "Train dataset:\n",
      "Loss: 2.0309\n",
      "Accuracy: 0.9648\n",
      "Precision: 0.4816\n",
      "Recall: 0.8771\n",
      "F1-score: 0.5806\n",
      "----------------------------------\n",
      "Eval dataset:\n",
      "Loss: 2.1817\n",
      "Accuracy: 0.9576\n",
      "Precision: 0.4180\n",
      "Recall: 0.6800\n",
      "F1-score: 0.4949\n",
      "----------------------------------\n",
      "Epoch 12/20----------------------\n",
      "Train dataset:\n",
      "Loss: 2.0256\n",
      "Accuracy: 0.9701\n",
      "Precision: 0.5135\n",
      "Recall: 0.8900\n",
      "F1-score: 0.6106\n",
      "----------------------------------\n",
      "Eval dataset:\n",
      "Loss: 2.1786\n",
      "Accuracy: 0.9629\n",
      "Precision: 0.4455\n",
      "Recall: 0.6843\n",
      "F1-score: 0.5183\n",
      "----------------------------------\n",
      "Epoch 13/20----------------------\n",
      "Train dataset:\n",
      "Loss: 2.0202\n",
      "Accuracy: 0.9708\n",
      "Precision: 0.5251\n",
      "Recall: 0.8946\n",
      "F1-score: 0.6221\n",
      "----------------------------------\n",
      "Eval dataset:\n",
      "Loss: 2.1745\n",
      "Accuracy: 0.9633\n",
      "Precision: 0.4489\n",
      "Recall: 0.6891\n",
      "F1-score: 0.5235\n",
      "----------------------------------\n",
      "Epoch 14/20----------------------\n",
      "Train dataset:\n",
      "Loss: 2.0157\n",
      "Accuracy: 0.9726\n",
      "Precision: 0.5448\n",
      "Recall: 0.9010\n",
      "F1-score: 0.6440\n",
      "----------------------------------\n",
      "Eval dataset:\n",
      "Loss: 2.1776\n",
      "Accuracy: 0.9649\n",
      "Precision: 0.4470\n",
      "Recall: 0.6808\n",
      "F1-score: 0.5185\n",
      "----------------------------------\n",
      "Epoch 15/20----------------------\n",
      "Train dataset:\n",
      "Loss: 2.0136\n",
      "Accuracy: 0.9727\n",
      "Precision: 0.5346\n",
      "Recall: 0.9039\n",
      "F1-score: 0.6328\n",
      "----------------------------------\n",
      "Eval dataset:\n",
      "Loss: 2.1768\n",
      "Accuracy: 0.9647\n",
      "Precision: 0.4520\n",
      "Recall: 0.6829\n",
      "F1-score: 0.5234\n",
      "----------------------------------\n",
      "Epoch 16/20----------------------\n",
      "Train dataset:\n",
      "Loss: 2.0099\n",
      "Accuracy: 0.9731\n",
      "Precision: 0.5481\n",
      "Recall: 0.9079\n",
      "F1-score: 0.6501\n",
      "----------------------------------\n",
      "Eval dataset:\n",
      "Loss: 2.1798\n",
      "Accuracy: 0.9647\n",
      "Precision: 0.4522\n",
      "Recall: 0.6768\n",
      "F1-score: 0.5240\n",
      "----------------------------------\n",
      "Epoch 17/20----------------------\n",
      "Train dataset:\n",
      "Loss: 2.0102\n",
      "Accuracy: 0.9732\n",
      "Precision: 0.5403\n",
      "Recall: 0.9088\n",
      "F1-score: 0.6396\n",
      "----------------------------------\n",
      "Eval dataset:\n",
      "Loss: 2.1773\n",
      "Accuracy: 0.9646\n",
      "Precision: 0.4445\n",
      "Recall: 0.6811\n",
      "F1-score: 0.5135\n",
      "----------------------------------\n",
      "Epoch 18/20----------------------\n",
      "Train dataset:\n",
      "Loss: 2.0055\n",
      "Accuracy: 0.9747\n",
      "Precision: 0.5605\n",
      "Recall: 0.9126\n",
      "F1-score: 0.6628\n",
      "----------------------------------\n",
      "Eval dataset:\n",
      "Loss: 2.1796\n",
      "Accuracy: 0.9659\n",
      "Precision: 0.4519\n",
      "Recall: 0.6802\n",
      "F1-score: 0.5229\n",
      "----------------------------------\n",
      "Epoch 19/20----------------------\n",
      "Train dataset:\n",
      "Loss: 2.0047\n",
      "Accuracy: 0.9761\n",
      "Precision: 0.5546\n",
      "Recall: 0.9147\n",
      "F1-score: 0.6532\n",
      "----------------------------------\n",
      "Eval dataset:\n",
      "Loss: 2.1791\n",
      "Accuracy: 0.9672\n",
      "Precision: 0.4543\n",
      "Recall: 0.6774\n",
      "F1-score: 0.5226\n",
      "----------------------------------\n",
      "Epoch 20/20----------------------\n",
      "Train dataset:\n",
      "Loss: 2.0047\n",
      "Accuracy: 0.9785\n",
      "Precision: 0.5823\n",
      "Recall: 0.9118\n",
      "F1-score: 0.6734\n",
      "----------------------------------\n",
      "Eval dataset:\n",
      "Loss: 2.1815\n",
      "Accuracy: 0.9702\n",
      "Precision: 0.4848\n",
      "Recall: 0.6789\n",
      "F1-score: 0.5473\n",
      "----------------------------------\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T22:30:14.572276Z",
     "start_time": "2024-05-26T22:30:14.456333Z"
    }
   },
   "source": [
    "# i = np.random.randint(0, x_test.shape[0])\n",
    "i = 0\n",
    "sentence = [w[0] for w in sentences[i]]\n",
    "print(sentence)\n",
    "\n",
    "true_labels = [w[2] for w in sentences[i]]\n",
    "print(true_labels)\n",
    "\n",
    "hashed_sentence = [hash_string(w) for w in sentence]\n",
    "print(hashed_sentence)\n",
    "\n",
    "s = torch.tensor(\n",
    "    [\n",
    "        hashed_sentence,\n",
    "    ]\n",
    ").to(device)\n",
    "print(s)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    p = np.argmax(model(s).cpu(), axis=-1)\n",
    "\n",
    "print(\"{:15}{:5}\\t {}\\n\".format(\"Word\", \"True\", \"Pred\"))\n",
    "\n",
    "predictions = p[0]\n",
    "for idx, word in enumerate(sentence):\n",
    "    print(\"{:15}{}\\t{}\".format(word, true_labels[idx], tags[predictions[idx]]))\n",
    "\n",
    "\n",
    "# for w, true, pred in zip(x_test[i], y_test[i], p[0]):\n",
    "#     # if words[w] == \"ENDPAD\":\n",
    "#     #     break\n",
    "#     print(\"{:15}{}\\t{}\".format(words[w], tags[true], tags[pred]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n",
      "[96844, 19376, 40914, 5097, 89921, 94304, 79733, 51786, 96443, 18221, 76265, 91958, 7399, 78694, 12524, 18221, 10937, 19376, 43879, 63804, 86782, 7986, 81819, 61285]\n",
      "tensor([[96844, 19376, 40914,  5097, 89921, 94304, 79733, 51786, 96443, 18221,\n",
      "         76265, 91958,  7399, 78694, 12524, 18221, 10937, 19376, 43879, 63804,\n",
      "         86782,  7986, 81819, 61285]], device='cuda:0')\n",
      "Word           True \t Pred\n",
      "\n",
      "Thousands      O\tO\n",
      "of             O\tO\n",
      "demonstrators  O\tO\n",
      "have           O\tO\n",
      "marched        O\tO\n",
      "through        O\tO\n",
      "London         B-geo\tB-geo\n",
      "to             O\tO\n",
      "protest        O\tO\n",
      "the            O\tO\n",
      "war            O\tO\n",
      "in             O\tO\n",
      "Iraq           B-geo\tB-geo\n",
      "and            O\tO\n",
      "demand         O\tO\n",
      "the            O\tO\n",
      "withdrawal     O\tO\n",
      "of             O\tO\n",
      "British        B-gpe\tB-gpe\n",
      "troops         O\tO\n",
      "from           O\tO\n",
      "that           O\tO\n",
      "country        O\tO\n",
      ".              O\tO\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T22:30:17.506514Z",
     "start_time": "2024-05-26T22:30:17.503177Z"
    }
   },
   "source": [
    "model_state = {\n",
    "    \"model_state_dict\": model.state_dict()\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T22:30:18.978360Z",
     "start_time": "2024-05-26T22:30:18.854497Z"
    }
   },
   "source": "torch.save(model_state, '/home/irek/PycharmProjects/zprp-ner-active_learning/new_model.pth')",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
